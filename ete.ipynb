{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75b17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PCA model successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load original 512D embeddings\n",
    "with open(\"face_embeddings.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "embeddings = np.array(data[\"embeddings\"])\n",
    "\n",
    "# Create and fit PCA model to reduce from 512 to 128 dimensions\n",
    "pca = PCA(n_components=128)\n",
    "pca.fit(embeddings)\n",
    "\n",
    "# Save using your current environment\n",
    "with open(\"pca_512_to_128.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "print(\"âœ… PCA model successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade94221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pca_reducer import load_pca_model\n",
    "\n",
    "# Load PCA\n",
    "pca = load_pca_model(\"pca_512_to_128.pkl\")\n",
    "\n",
    "# Assume you have: `embedding_512` from InsightFace\n",
    "embedding_128 = pca.transform([embedding_512])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11fd30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded trained PCA for 128D reduction.\n",
      "[DONE] Converted 5004 embeddings to 128D and saved to face_embeddings_128.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from modules.pca_reducer import load_pca_model\n",
    "\n",
    "# File paths\n",
    "input_file = \"face_embeddings.json\"\n",
    "output_file = \"face_embeddings_128.json\"\n",
    "pca_model_path = \"pca_512_to_128.pkl\"\n",
    "\n",
    "# Load 512D embeddings\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    embeddings_512 = np.array(data[\"embeddings\"])\n",
    "    labels = data[\"labels\"]\n",
    "\n",
    "# Load trained PCA model\n",
    "pca = load_pca_model(pca_model_path)\n",
    "\n",
    "# Convert to 128D\n",
    "embeddings_128 = pca.transform(embeddings_512)\n",
    "\n",
    "# Save to new JSON\n",
    "output_data = {\n",
    "    \"embeddings\": embeddings_128.tolist(),\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(output_data, f)\n",
    "\n",
    "print(f\"[DONE] Converted {len(embeddings_128)} embeddings to 128D and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cbb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d7ef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 12320 values to 'projection_matrix.txt'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load all float32 values from the .dat file\n",
    "data = np.fromfile(\"neuralhash_128x96_seed1.dat\", dtype=np.float32)\n",
    "\n",
    "# Save to text file\n",
    "np.savetxt(\"projection_matrix.txt\", data, fmt=\"%.8f\")\n",
    "\n",
    "print(f\"âœ… Saved {data.size} values to 'projection_matrix.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050907f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12320 into shape (128,96)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuralhash_128x96_seed1.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reshape to 128Ã—96 matrix\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save in matrix format to text\u001b[39;00m\n\u001b[0;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojection_matrix.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, matrix, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.8f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 12320 into shape (128,96)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load float32 values\n",
    "data = np.fromfile(\"neuralhash_128x96_seed1.dat\", dtype=np.float32)\n",
    "\n",
    "# Reshape to 128Ã—96 matrix\n",
    "matrix = data.reshape((128, 96))\n",
    "\n",
    "# Save in matrix format to text\n",
    "np.savetxt(\"projection_matrix.txt\", matrix, fmt=\"%.8f\")\n",
    "\n",
    "print(f\"âœ… Saved {matrix.shape} matrix to 'projection_matrix.txt'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9641b8",
   "metadata": {},
   "source": [
    "Problem solved the first 32 values are metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a72b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded and saved clean projection matrix of shape (128, 96)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load all float32 values\n",
    "data = np.fromfile(\"neuralhash_128x96_seed1.dat\", dtype=np.float32)\n",
    "\n",
    "# Skip first 32 values (metadata)\n",
    "matrix_data = data[32:32 + 128 * 96]\n",
    "\n",
    "# Reshape into 128Ã—96 matrix\n",
    "proj_matrix = matrix_data.reshape((128, 96))\n",
    "\n",
    "# Save to file\n",
    "np.savetxt(\"projection_matrix_cleaned.txt\", proj_matrix, fmt=\"%.8f\")\n",
    "\n",
    "print(f\"âœ… Loaded and saved clean projection matrix of shape {proj_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6323b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22616\\114390261.py:6: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  dataset_path = \"C:\\\\Users\\\\ASUS\\Desktop\\\\VGGFace_Dataset\" # ðŸ” CHANGE this to your dataset folder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated 1080 pairs and saved to 'test_pairs.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "dataset_path = \"C:\\\\Users\\\\ASUS\\Desktop\\\\VGGFace_Dataset\" # ðŸ” CHANGE this to your dataset folder\n",
    "output_csv = \"test_pairs.csv\"\n",
    "\n",
    "# Get all people folders (non-empty)\n",
    "people_dirs = [os.path.join(dataset_path, d) for d in os.listdir(dataset_path)\n",
    "               if os.path.isdir(os.path.join(dataset_path, d)) and len(os.listdir(os.path.join(dataset_path, d))) >= 2]\n",
    "\n",
    "pairs = []\n",
    "\n",
    "# Generate Genuine Pairs (same identity)\n",
    "for person_dir in people_dirs:\n",
    "    images = glob(os.path.join(person_dir, \"*.jpg\"))\n",
    "    if len(images) >= 2:\n",
    "        img1, img2 = random.sample(images, 2)\n",
    "        pairs.append((img1, img2, 1))  # label 1 = same person\n",
    "\n",
    "# Generate Impostor Pairs (different identities)\n",
    "for _ in range(len(pairs)):\n",
    "    p1, p2 = random.sample(people_dirs, 2)\n",
    "    img1_list = glob(os.path.join(p1, \"*.jpg\"))\n",
    "    img2_list = glob(os.path.join(p2, \"*.jpg\"))\n",
    "    if img1_list and img2_list:\n",
    "        img1 = random.choice(img1_list)\n",
    "        img2 = random.choice(img2_list)\n",
    "        pairs.append((img1, img2, 0))  # label 0 = different people\n",
    "\n",
    "# Save to CSV\n",
    "with open(output_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"img1\", \"img2\", \"label\"])\n",
    "    writer.writerows(pairs)\n",
    "\n",
    "print(f\"âœ… Generated {len(pairs)} pairs and saved to '{output_csv}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a0e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded trained PCA for 128D reduction.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[WARNING] Skipping missing image(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg1_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg2_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m emb1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m emb2 \u001b[38;5;241m=\u001b[39m extract_embedding(img2)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m emb1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m emb2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\FYP\\Arc\\Face_Recognition\\modules\\embedding_extractor.py:9\u001b[0m, in \u001b[0;36mextract_embedding\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_embedding\u001b[39m(image_path):\n\u001b[1;32m----> 9\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     faces \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget(img)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d659d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\face_rec\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator PCA from version 1.6.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded trained PCA for 128D reduction.\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000028\\0401_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000028\\0006_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000122\\0202_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000122\\0248_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000170\\0195_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000170\\0260_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000298\\0121_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000298\\0173_03.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000501\\0223_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000501\\0359_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001296\\0249_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001296\\0169_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000288\\0357_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000452\\0112_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000498\\0430_02.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000145\\0164_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000282\\0382_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000382\\0006_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000263\\0336_02.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000221\\0276_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000043\\0133_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000182\\0034_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000140\\0157_02.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000238\\0438_03.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000164\\0284_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000740\\0093_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000086\\0218_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001296\\0197_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000299\\0429_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001146\\0365_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000854\\0017_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000419\\0204_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000033\\0407_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000001\\0276_01.jpg\n",
      "\n",
      "ðŸ“Š Cosine Similarity Metrics:\n",
      "Accuracy: 0.7920978363123237\n",
      "Precision: 1.0\n",
      "Recall: 0.5861423220973783\n",
      "F1 Score: 0.7390791027154664\n",
      "Confusion Matrix:\n",
      " [[529   0]\n",
      " [221 313]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from modules.embedding_extractor import extract_embedding\n",
    "from modules.pca_reducer import load_pca_model, reduce_embedding\n",
    "from modules.hashing import load_projection_matrix, compute_hash_from_embedding\n",
    "from scipy.spatial.distance import cosine\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load PCA and projection matrix\n",
    "pca = load_pca_model(\"pca_512_to_128.pkl\")\n",
    "proj = load_projection_matrix(\"neuralhash_128x96_seed1.dat\")\n",
    "\n",
    "# Load CSV\n",
    "pairs = []\n",
    "with open(\"test_pairs.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        pairs.append((row[\"img1\"], row[\"img2\"], int(row[\"label\"])))\n",
    "\n",
    "cosine_similarities = []\n",
    "hamming_distances = []\n",
    "true_labels = []\n",
    "\n",
    "for img1_path, img2_path, label in pairs:\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    if img1 is None or img2 is None:\n",
    "        print(f\"[WARNING] Skipping missing image(s): {img1_path}, {img2_path}\")\n",
    "        continue\n",
    "\n",
    "    emb1 = extract_embedding(img1)\n",
    "    emb2 = extract_embedding(img2)\n",
    "\n",
    "    if emb1 is None or emb2 is None:\n",
    "        print(f\"[WARNING] Skipping undetected face(s): {img1_path}, {img2_path}\")\n",
    "        continue\n",
    "\n",
    "    # Cosine similarity (higher = more similar)\n",
    "    cos_sim = 1 - cosine(emb1, emb2)\n",
    "    cosine_similarities.append(cos_sim)\n",
    "\n",
    "    # Hash comparison (lower = more similar)\n",
    "    hash1 = compute_hash_from_embedding(reduce_embedding(pca, emb1), proj)\n",
    "    hash2 = compute_hash_from_embedding(reduce_embedding(pca, emb2), proj)\n",
    "    hamming = np.sum(hash1 != hash2)\n",
    "    hamming_distances.append(hamming)\n",
    "\n",
    "    true_labels.append(label)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate cosine similarity\n",
    "# -----------------------------\n",
    "cosine_preds = [1 if sim > 0.5 else 0 for sim in cosine_similarities]  # Adjust threshold as needed\n",
    "print(\"\\nðŸ“Š Cosine Similarity Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, cosine_preds))\n",
    "print(\"Precision:\", precision_score(true_labels, cosine_preds))\n",
    "print(\"Recall:\", recall_score(true_labels, cosine_preds))\n",
    "print(\"F1 Score:\", f1_score(true_labels, cosine_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, cosine_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdafc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\face_rec\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator PCA from version 1.6.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded trained PCA for 128D reduction.\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000028\\0401_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000028\\0006_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000122\\0202_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000122\\0248_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000170\\0195_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000170\\0260_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000298\\0121_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000298\\0173_03.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000501\\0223_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000501\\0359_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001296\\0249_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001296\\0169_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000288\\0357_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000452\\0112_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000498\\0430_02.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000145\\0164_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000282\\0382_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000382\\0006_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000263\\0336_02.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000221\\0276_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000043\\0133_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000182\\0034_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000140\\0157_02.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000238\\0438_03.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000164\\0284_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000740\\0093_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000086\\0218_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001296\\0197_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000299\\0429_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n001146\\0365_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000854\\0017_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000419\\0204_01.jpg\n",
      "[WARNING] Skipping undetected face(s): C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000033\\0407_01.jpg, C:\\Users\\ASUS\\Desktop\\VGGFace_Dataset\\n000001\\0276_01.jpg\n",
      "\n",
      "ðŸ“Š Cosine Similarity Metrics:\n",
      "Accuracy: 0.6077140169332079\n",
      "Precision: 1.0\n",
      "Recall: 0.21910112359550563\n",
      "F1 Score: 0.35944700460829493\n",
      "Confusion Matrix:\n",
      " [[529   0]\n",
      " [417 117]]\n",
      "\n",
      "ðŸ“Š Hamming Distance Metrics (96-bit Hashes):\n",
      "Accuracy: 0.735653809971778\n",
      "Precision: 0.996078431372549\n",
      "Recall: 0.4756554307116105\n",
      "F1 Score: 0.6438529784537389\n",
      "Confusion Matrix:\n",
      " [[528   1]\n",
      " [280 254]]\n",
      "ROC AUC (Cosine): 0.9780484696586734\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from modules.embedding_extractor import extract_embedding\n",
    "from modules.pca_reducer import load_pca_model, reduce_embedding\n",
    "from modules.hashing import load_projection_matrix, compute_hash_from_embedding\n",
    "from scipy.spatial.distance import cosine\n",
    "import cv2\n",
    "\n",
    "# Load PCA and projection matrix\n",
    "pca = load_pca_model(\"pca_512_to_128.pkl\")\n",
    "proj = load_projection_matrix(\"neuralhash_128x96_seed1.dat\")\n",
    "\n",
    "# Load CSV\n",
    "pairs = []\n",
    "with open(\"test_pairs.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        pairs.append((row[\"img1\"], row[\"img2\"], int(row[\"label\"])))\n",
    "\n",
    "cosine_similarities = []\n",
    "hamming_distances = []\n",
    "true_labels = []\n",
    "\n",
    "for img1_path, img2_path, label in pairs:\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    if img1 is None or img2 is None:\n",
    "        print(f\"[WARNING] Skipping missing image(s): {img1_path}, {img2_path}\")\n",
    "        continue\n",
    "\n",
    "    emb1 = extract_embedding(img1)\n",
    "    emb2 = extract_embedding(img2)\n",
    "\n",
    "    if emb1 is None or emb2 is None:\n",
    "        print(f\"[WARNING] Skipping undetected face(s): {img1_path}, {img2_path}\")\n",
    "        continue\n",
    "\n",
    "    # Cosine similarity (higher = more similar)\n",
    "    cos_sim = 1 - cosine(emb1, emb2)\n",
    "    cosine_similarities.append(cos_sim)\n",
    "\n",
    "    # Hash comparison (lower = more similar)\n",
    "    hash1 = compute_hash_from_embedding(reduce_embedding(pca, emb1), proj)\n",
    "    hash2 = compute_hash_from_embedding(reduce_embedding(pca, emb2), proj)\n",
    "    hamming = np.sum(hash1 != hash2)\n",
    "    hamming_distances.append(hamming)\n",
    "\n",
    "    true_labels.append(label)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate cosine similarity\n",
    "# -----------------------------\n",
    "cosine_preds = [1 if sim > 0.65 else 0 for sim in cosine_similarities]  # Adjust threshold as needed\n",
    "print(\"\\nðŸ“Š Cosine Similarity Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, cosine_preds))\n",
    "print(\"Precision:\", precision_score(true_labels, cosine_preds))\n",
    "print(\"Recall:\", recall_score(true_labels, cosine_preds))\n",
    "print(\"F1 Score:\", f1_score(true_labels, cosine_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, cosine_preds))\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate Hamming distance\n",
    "# -----------------------------\n",
    "hamming_preds = [1 if dist < 30 else 0 for dist in hamming_distances]  # Adjust threshold as needed\n",
    "print(\"\\nðŸ“Š Hamming Distance Metrics (96-bit Hashes):\")\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, hamming_preds))\n",
    "print(\"Precision:\", precision_score(true_labels, hamming_preds))\n",
    "print(\"Recall:\", recall_score(true_labels, hamming_preds))\n",
    "print(\"F1 Score:\", f1_score(true_labels, hamming_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, hamming_preds))\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: ROC AUC for cosine similarity\n",
    "# -----------------------------\n",
    "try:\n",
    "    print(\"ROC AUC (Cosine):\", roc_auc_score(true_labels, cosine_similarities))\n",
    "except:\n",
    "    print(\"Not enough class variance for ROC AUC.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f5678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96a214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
